---
title: "M_learning-recognition"
author: "GÃ¶zem Turan"
date: "11 5 2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE, message=FALSE}
library(lme4) 
library(car)
library(tidyr)
library(rstatix)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(ez)
library(psycho)
library(sjPlot)
library(plyr)

```

# Relationship between learning efficiency and SDT
```{r}
df_tra <- read.csv("L:/2_Research/2_Analysis_Folder/MemVio//part1_RTout.csv")
df_recog <- read.csv("L:/2_Research/2_Analysis_Folder/MemVio//part3_RTout.csv")

```

## Preparations for training
```{r}
# to calculative individual values
df_tra <- ddply(df_tra, .(participant), summarize, cummean = cummean(corrAns))

# to add trials
df_tra <- within(df_tra, {
    trial <- ave(as.character(participant), participant, FUN = seq_along)
})

df_tra$trial <- as.numeric(df_tra$trial) # make it numeric

```
```{r}
# have the last 1/3 of the data

df_tra <- df_tra[df_tra$trial >= 133, ]

# take mean cumm accuracy
df_cum <- aggregate(cummean ~ participant, mean, data = df_tra)

```


## Preparations for recognition
```{r}
df_recog <- df_recog[!df_recog$on == "new", ] #bye new pictures

```

# MERGE Data
```{r}

test <- merge(x = df_recog, y = df_cum, by = c("participant"), all.y = TRUE)

test$pe <- factor(test$pe, levels=c("lowPE", "medPE", "highPE")) #pe

test$participant <- as.factor(test$participant) #participants

test <- na.omit(test)

```

# Model: Learning efficiency to predict prop old by pe group
```{r}

#m1 <- lm(corrAns ~ 1, data = test) # simple
#summary(m1)

#m2 <- lmer(corrAns~1+(1|participant), data = test) # only with random intercept
#summary(m2)

#anova(m2, m1)

#m3 <- lmer(corrAns ~ cummean + (1+cummean|participant), data = test) # random intercept and effect
#summary(m3)
#anova(m3,m2)

m4 <- lmer(corrAns ~ cummean*pe + (1|participant), data = test) # interaction
summary(m4)
#anova(m4,m3)

m5 <- lmer(corrAns ~ cummean*pe + (cummean*pe|participant), data = test) # interaction and a slope
summary(m5)
anova(m4, m5)
Anova(m5)
emmeans(m5, pairwise ~ pe)


```

# PLOT
```{r}
test$random.slope.int.preds <- predict(m5)

ggplot(test, aes(x=cummean, y=random.slope.int.preds, group = pe, colour = pe)) +
  geom_point() +
  geom_smooth(method=lm, se = T)+
  labs(x="Learning - Cumulative Accuracy", y="Prop Old") + 
  scale_colour_discrete('pe') +
  theme_classic()

#tab_model(m4)

```

# only for high conf trials
```{r}
testC <- test[!test$conf > 2, ]

```

# Model: Learning efficiency to predict prop old by pe group
```{r}

m6 <- lmer(corrAns ~ cummean*pe + (1|participant), data = testC) # interaction
summary(m6)

m7 <- lmer(corrAns ~ cummean*pe + (cummean*pe|participant), data = testC) # interaction and a slope
summary(m7)
anova(m6, m7)
Anova(m7)

```

# PLOT
```{r}
testC$random.slope.int.preds <- predict(m7)

ggplot(testC, aes(x=cummean, y=random.slope.int.preds, group = pe, colour = pe)) +
  geom_point() +
  geom_smooth(method=lm, se = T)+
  labs(x="Learning - Cumulative Accuracy", y="Prop Old") + 
  scale_colour_discrete('pe') +
  theme_classic()

#tab_model(m6)

```
